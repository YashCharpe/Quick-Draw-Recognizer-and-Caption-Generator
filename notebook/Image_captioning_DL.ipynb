{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bwwk4uxRz6A"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc06pTaBbl72",
        "outputId": "ce341a46-9c7c-4953-ab0b-a4f47c883800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be DOWNGRADED:\n",
            "  libcudnn8\n",
            "0 upgraded, 0 newly installed, 1 downgraded, 1 to remove and 3 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 1,392 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n",
            "Fetched 430 MB in 14s (30.6 MB/s)\n",
            "(Reading database ... 123991 files and directories currently installed.)\n",
            "Removing libcudnn8-dev (8.1.1.33-1+cuda11.2) ...\n",
            "update-alternatives: removing manually selected alternative - switching libcudnn to auto mode\n",
            "\u001b[1mdpkg:\u001b[0m \u001b[1;33mwarning:\u001b[0m downgrading libcudnn8 from 8.1.1.33-1+cuda11.2 to 8.1.0.77-1+cuda11.2\n",
            "(Reading database ... 123968 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.1.1.33-1+cuda11.2) ...\n",
            "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"
          ]
        }
      ],
      "source": [
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2R1hQGtZEi8Y"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y tensorflow estimator keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5Xbt8BkPv8Ou",
        "outputId": "cd3b0b5b-06f0-4ae4-e564-41badce43046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting tensorflow\n",
            "  Downloading tensorflow-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 6.2 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.7/dist-packages (4.6.0)\n",
            "Collecting tensorflow_datasets\n",
            "  Downloading tensorflow_datasets-4.7.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 27.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 36.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.11.23-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 48.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 66.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.10.2)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.9.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.3.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (4.64.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.11.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (5.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.57.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, tensorflow-text, tensorflow-datasets\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow-datasets\n",
            "    Found existing installation: tensorflow-datasets 4.6.0\n",
            "    Uninstalling tensorflow-datasets-4.6.0:\n",
            "      Successfully uninstalled tensorflow-datasets-4.6.0\n",
            "Successfully installed flatbuffers-22.11.23 keras-2.11.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-datasets-4.7.0 tensorflow-estimator-2.11.0 tensorflow-text-2.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U tensorflow_text tensorflow tensorflow_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TGZmOuqMia9"
      },
      "outputs": [],
      "source": [
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8l4RJ0XRPEm"
      },
      "outputs": [],
      "source": [
        "import concurrent.futures\n",
        "import collections\n",
        "import dataclasses\n",
        "import hashlib\n",
        "import itertools\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import pathlib\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "import urllib.request\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import requests\n",
        "import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqGXX9Dc5c0v"
      },
      "source": [
        "#### Flickr8k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaNy_l7tGuAZ"
      },
      "outputs": [],
      "source": [
        "def flickr8k(path='flickr8k'):\n",
        "  path = pathlib.Path(path)\n",
        "\n",
        "  if len(list(path.rglob('*'))) < 16197:\n",
        "    tf.keras.utils.get_file(\n",
        "        origin='https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip',\n",
        "        cache_dir='.',\n",
        "        cache_subdir=path,\n",
        "        extract=True)\n",
        "    tf.keras.utils.get_file(\n",
        "        origin='https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip',\n",
        "        cache_dir='.',\n",
        "        cache_subdir=path,\n",
        "        extract=True)\n",
        "    \n",
        "  captions = (path/\"Flickr8k.token.txt\").read_text().splitlines()\n",
        "  captions = (line.split('\\t') for line in captions)\n",
        "  captions = ((fname.split('#')[0], caption) for (fname, caption) in captions)\n",
        "\n",
        "  cap_dict = collections.defaultdict(list)\n",
        "  for fname, cap in captions:\n",
        "    cap_dict[fname].append(cap)\n",
        "\n",
        "  train_files = (path/'Flickr_8k.trainImages.txt').read_text().splitlines()\n",
        "  train_captions = [(str(path/'Flicker8k_Dataset'/fname), cap_dict[fname]) for fname in train_files]\n",
        "\n",
        "  test_files = (path/'Flickr_8k.testImages.txt').read_text().splitlines()\n",
        "  test_captions = [(str(path/'Flicker8k_Dataset'/fname), cap_dict[fname]) for fname in test_files]\n",
        "\n",
        "  train_ds = tf.data.experimental.from_list(train_captions)\n",
        "  test_ds = tf.data.experimental.from_list(test_captions)\n",
        "\n",
        "  return train_ds, test_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQICBAF4FmSL"
      },
      "source": [
        "#### Captions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQwnxXZXRl12"
      },
      "outputs": [],
      "source": [
        "def conceptual_captions(*, data_dir=\"conceptual_captions\", num_train, num_val):\n",
        "  def iter_index(index_path):\n",
        "    with open(index_path) as f:\n",
        "      for line in f:\n",
        "        caption, url = line.strip().split('\\t')\n",
        "        yield caption, url\n",
        "\n",
        "  def download_image_urls(data_dir, urls):\n",
        "    ex = concurrent.futures.ThreadPoolExecutor(max_workers=100)\n",
        "    def save_image(url):\n",
        "      hash = hashlib.sha1(url.encode())\n",
        "      # Name the files after the hash of the URL.\n",
        "      file_path = data_dir/f'{hash.hexdigest()}.jpeg'\n",
        "      if file_path.exists():\n",
        "        # Only download each file once.\n",
        "        return file_path\n",
        "\n",
        "      try:\n",
        "        result = requests.get(url, timeout=5)\n",
        "      except Exception:\n",
        "        file_path = None\n",
        "      else:\n",
        "        file_path.write_bytes(result.content)\n",
        "      return file_path\n",
        "    \n",
        "    result = []\n",
        "    out_paths = ex.map(save_image, urls)\n",
        "    for file_path in tqdm.tqdm(out_paths, total=len(urls)):\n",
        "      result.append(file_path)\n",
        "\n",
        "    return result\n",
        "\n",
        "  def ds_from_index_file(index_path, data_dir, count):\n",
        "    data_dir.mkdir(exist_ok=True)\n",
        "    index = list(itertools.islice(iter_index(index_path), count))\n",
        "    captions = [caption for caption, url in index]\n",
        "    urls = [url for caption, url in index]\n",
        "\n",
        "    paths = download_image_urls(data_dir, urls)\n",
        "\n",
        "    new_captions = []\n",
        "    new_paths = []\n",
        "    for cap, path in zip(captions, paths):\n",
        "      if path is None:\n",
        "        # Download failed, so skip this pair.\n",
        "        continue\n",
        "      new_captions.append(cap)\n",
        "      new_paths.append(path)\n",
        "    \n",
        "    new_paths = [str(p) for p in new_paths]\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices((new_paths, new_captions))\n",
        "    ds = ds.map(lambda path,cap: (path, cap[tf.newaxis])) # 1 caption per image\n",
        "    return ds\n",
        "\n",
        "  data_dir = pathlib.Path(data_dir)\n",
        "  train_index_path = tf.keras.utils.get_file(\n",
        "    origin='https://storage.googleapis.com/gcc-data/Train/GCC-training.tsv',\n",
        "    cache_subdir=data_dir,\n",
        "    cache_dir='.')\n",
        "  \n",
        "  val_index_path = tf.keras.utils.get_file(\n",
        "    origin='https://storage.googleapis.com/gcc-data/Validation/GCC-1.1.0-Validation.tsv',\n",
        "    cache_subdir=data_dir,\n",
        "    cache_dir='.')\n",
        "  \n",
        "  train_raw = ds_from_index_file(train_index_path, data_dir=data_dir/'train', count=num_train)\n",
        "  test_raw = ds_from_index_file(val_index_path, data_dir=data_dir/'val', count=num_val)\n",
        "\n",
        "  return train_raw, test_raw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBAagBw5p-TM"
      },
      "source": [
        "#### Download the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFtTZaobquNr"
      },
      "source": [
        "The Flickr8k is a good choice because it contains 5-captions per image, more data for a smaller download."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EJySPbzJ4Wxw",
        "outputId": "786d7a92-f520-49d1-8d0c-7c2e66703a19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\n",
            "1115419746/1115419746 [==============================] - 57s 0us/step\n",
            "Downloading data from https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\n",
            "2340801/2340801 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "choose = 'flickr8k'\n",
        "\n",
        "if choose == 'flickr8k':\n",
        "  train_raw, test_raw = flickr8k()\n",
        "else:\n",
        "  train_raw, test_raw = conceptual_captions(num_train=10000, num_val=5000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UAc275FHxm8"
      },
      "source": [
        "The loaders for both datasets above return `tf.data.Dataset`s containing `(image_path, captions)` pairs. The Flickr8k dataset contains 5 captions per image, while Conceptual Captions has 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sAQSps5F8RQI",
        "outputId": "e67b82ab-aad5-402e-9c69-490a7f8cf04c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(5,), dtype=tf.string, name=None))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_raw.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xIa0ZaP4tBez",
        "outputId": "535c3add-0a53-41bf-b8e7-1000ffb73fab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'flickr8k/Flicker8k_Dataset/2513260012_03d33305cf.jpg', shape=(), dtype=string)\n",
            "tf.Tensor(\n",
            "[b'A black dog is running after a white dog in the snow .'\n",
            " b'Black dog chasing brown dog through snow'\n",
            " b'Two dogs chase each other across the snowy ground .'\n",
            " b'Two dogs play together in the snow .'\n",
            " b'Two dogs running through a low lying body of water .'], shape=(5,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for ex_path, ex_captions in train_raw.take(1):\n",
        "  print(ex_path)\n",
        "  print(ex_captions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cSW4u-ORPFQ"
      },
      "source": [
        "### Image feature extractor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IlUckK8Zfikv",
        "outputId": "310193ff-814b-406d-c029-1c3d9c2dfc54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n",
            "4334752/4334752 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "IMAGE_SHAPE=(224, 224, 3)\n",
        "mobilenet = tf.keras.applications.MobileNetV3Small(\n",
        "    input_shape=IMAGE_SHAPE,\n",
        "    include_top=False,\n",
        "    include_preprocessing=True)\n",
        "mobilenet.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zXR0217aRPFR"
      },
      "outputs": [],
      "source": [
        "def load_image(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.io.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, IMAGE_SHAPE[:-1])\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sY86n2i6wJNm"
      },
      "outputs": [],
      "source": [
        "test_img_batch = load_image(ex_path)[tf.newaxis, :]\n",
        "\n",
        "print(test_img_batch.shape)\n",
        "print(mobilenet(test_img_batch).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyqH3zFwRPFi"
      },
      "source": [
        "### Setup the text tokenizer/vectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NroZIzB90hD3"
      },
      "outputs": [],
      "source": [
        "def standardize(s):\n",
        "  s = tf.strings.lower(s)\n",
        "  s = tf.strings.regex_replace(s, f'[{re.escape(string.punctuation)}]', '')\n",
        "  s = tf.strings.join(['[START]', s, '[END]'], separator=' ')\n",
        "  return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9SQOXFsyS36"
      },
      "outputs": [],
      "source": [
        "# Use the top 5000 words for a vocabulary.\n",
        "vocabulary_size = 5000\n",
        "tokenizer = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=vocabulary_size,\n",
        "    standardize=standardize,\n",
        "    ragged=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJGE34aiRPFo"
      },
      "outputs": [],
      "source": [
        "tokenizer.adapt(train_raw.map(lambda fp,txt: txt).unbatch().batch(1024))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRahTDtWhJIf"
      },
      "outputs": [],
      "source": [
        "tokenizer.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2mGxD33JCxN"
      },
      "outputs": [],
      "source": [
        "t = tokenizer([['a cat in a hat'], ['a robot dog']])\n",
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Q44tNQVRPFt"
      },
      "outputs": [],
      "source": [
        "# Create mappings for words to indices and indices to words.\n",
        "word_to_index = tf.keras.layers.StringLookup(\n",
        "    mask_token=\"\",\n",
        "    vocabulary=tokenizer.get_vocabulary())\n",
        "index_to_word = tf.keras.layers.StringLookup(\n",
        "    mask_token=\"\",\n",
        "    vocabulary=tokenizer.get_vocabulary(),\n",
        "    invert=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qo-cfCX3LnHs"
      },
      "outputs": [],
      "source": [
        "w = index_to_word(t)\n",
        "w.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrUUfGc65vAT"
      },
      "outputs": [],
      "source": [
        "tf.strings.reduce_join(w, separator=' ', axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEWM9xrYcg45"
      },
      "source": [
        "### Prepare the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_Lqwl9NiGT0"
      },
      "outputs": [],
      "source": [
        "def match_shapes(images, captions):\n",
        "  caption_shape = einops.parse_shape(captions, 'b c')\n",
        "  captions = einops.rearrange(captions, 'b c -> (b c)')\n",
        "  images = einops.repeat(\n",
        "      images, 'b ... -> (b c) ...',\n",
        "      c = caption_shape['c'])\n",
        "  return images, captions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZGUsuGzUfzt"
      },
      "outputs": [],
      "source": [
        "for ex_paths, ex_captions in train_raw.batch(32).take(1):\n",
        "  break\n",
        "\n",
        "print('image paths:', ex_paths.shape)\n",
        "print('captions:', ex_captions.shape)\n",
        "print()\n",
        "\n",
        "ex_paths, ex_captions = match_shapes(images=ex_paths, captions=ex_captions)\n",
        "\n",
        "print('image_paths:', ex_paths.shape)\n",
        "print('captions:', ex_captions.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DsgQ_hZT4C2"
      },
      "outputs": [],
      "source": [
        "def prepare_txt(imgs, txts):\n",
        "  tokens = tokenizer(txts)\n",
        "\n",
        "  input_tokens = tokens[..., :-1]\n",
        "  label_tokens = tokens[..., 1:]\n",
        "  return (imgs, input_tokens), label_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_Pt9zldjQ0q"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(ds, tokenizer, batch_size=32, shuffle_buffer=1000):\n",
        "  # Load the images and make batches.\n",
        "  ds = (ds\n",
        "        .shuffle(10000)\n",
        "        .map(lambda path, caption: (load_image(path), caption))\n",
        "        .apply(tf.data.experimental.ignore_errors())\n",
        "        .batch(batch_size))\n",
        "\n",
        "  def to_tensor(inputs, labels):\n",
        "    (images, in_tok), out_tok = inputs, labels\n",
        "    return (images, in_tok.to_tensor()), out_tok.to_tensor()\n",
        "\n",
        "  return (ds\n",
        "          .map(match_shapes, tf.data.AUTOTUNE)\n",
        "          .unbatch()\n",
        "          .shuffle(shuffle_buffer)\n",
        "          .batch(batch_size)\n",
        "          .map(prepare_txt, tf.data.AUTOTUNE)\n",
        "          .map(to_tensor, tf.data.AUTOTUNE)\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KlhOG5cjQ0r"
      },
      "outputs": [],
      "source": [
        "train_ds = prepare_dataset(train_raw, tokenizer)\n",
        "train_ds.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7Zy9F3zX7i2"
      },
      "outputs": [],
      "source": [
        "test_ds = prepare_dataset(test_raw, tokenizer)\n",
        "test_ds.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZyKygJ8S8zW"
      },
      "source": [
        "### Save the image features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHKhSKhti6NS"
      },
      "source": [
        "Since the image feature extractor is not changing, and this tutorial is not using image augmentation, the image features can be cached. Same for the text tokenization. The time it takes to set up the cache is earned back on each epoch during training and validation. The code below defines two functions `save_dataset` and `load_dataset`: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9N1MX5ym6xm5"
      },
      "outputs": [],
      "source": [
        "def save_dataset(ds, save_path, image_model, tokenizer, shards=10, batch_size=32):\n",
        "  # Load the images and make batches.\n",
        "  ds = (ds\n",
        "        .map(lambda path, caption: (load_image(path), caption))\n",
        "        .apply(tf.data.experimental.ignore_errors())\n",
        "        .batch(batch_size))\n",
        "\n",
        "  # Run the feature extractor on each batch\n",
        "  # Don't do this in a .map, because tf.data runs on the CPU. \n",
        "  def gen():\n",
        "    for (images, captions) in tqdm.tqdm(ds): \n",
        "      feature_maps = image_model(images)\n",
        "\n",
        "      feature_maps, captions = match_shapes(feature_maps, captions)\n",
        "      yield feature_maps, captions\n",
        "\n",
        "  # Wrap the generator in a new tf.data.Dataset.\n",
        "  new_ds = tf.data.Dataset.from_generator(\n",
        "      gen,\n",
        "      output_signature=(\n",
        "          tf.TensorSpec(shape=image_model.output_shape),\n",
        "          tf.TensorSpec(shape=(None,), dtype=tf.string)))\n",
        "\n",
        "  # Apply the tokenization \n",
        "  new_ds = (new_ds\n",
        "            .map(prepare_txt, tf.data.AUTOTUNE)\n",
        "            .unbatch()\n",
        "            .shuffle(1000))\n",
        "\n",
        "  # Save the dataset into shard files.\n",
        "  def shard_func(i, item):\n",
        "    return i % shards\n",
        "  new_ds.enumerate().save(save_path, shard_func=shard_func)\n",
        "\n",
        "def load_dataset(save_path, batch_size=32, shuffle=1000, cycle_length=2):\n",
        "  def custom_reader_func(datasets):\n",
        "    datasets = datasets.shuffle(1000)\n",
        "    return datasets.interleave(lambda x: x, cycle_length=cycle_length)\n",
        "  \n",
        "  ds = tf.data.Dataset.load(save_path, reader_func=custom_reader_func)\n",
        "\n",
        "  def drop_index(i, x):\n",
        "    return x\n",
        "\n",
        "  ds = (ds\n",
        "        .map(drop_index, tf.data.AUTOTUNE)\n",
        "        .shuffle(shuffle)\n",
        "        .padded_batch(batch_size)\n",
        "        .prefetch(tf.data.AUTOTUNE))\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNdzrenxB3Yy"
      },
      "outputs": [],
      "source": [
        "save_dataset(train_raw, 'train_cache', mobilenet, tokenizer)\n",
        "save_dataset(test_raw, 'test_cache', mobilenet, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "798DtfH51UI8"
      },
      "source": [
        " </section>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI265LiDslr2"
      },
      "source": [
        "## Data ready for training\n",
        "\n",
        "After those preprocessing steps, here are the datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pwic2YCjHZmV"
      },
      "outputs": [],
      "source": [
        "train_ds = load_dataset('train_cache')\n",
        "test_ds = load_dataset('test_cache')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B80JXj7HloX"
      },
      "outputs": [],
      "source": [
        "train_ds.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJBEwuXLZQdw"
      },
      "outputs": [],
      "source": [
        "for (inputs, ex_labels) in train_ds.take(1):\n",
        "  (ex_img, ex_in_tok) = inputs\n",
        "\n",
        "print(ex_img.shape)\n",
        "print(ex_in_tok.shape)\n",
        "print(ex_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22R58DzZoF17"
      },
      "source": [
        "The input tokens and the labels are the same, just shifted by 1 step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7h5UGftn1hT"
      },
      "outputs": [],
      "source": [
        "print(ex_in_tok[0].numpy())\n",
        "print(ex_labels[0].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfICM49WFpIb"
      },
      "source": [
        "## A Transformer decoder model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ngm3SQMCaYU"
      },
      "source": [
        "### Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P91LU2F0a9Ga"
      },
      "outputs": [],
      "source": [
        "class SeqEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, vocab_size, max_length, depth):\n",
        "    super().__init__()\n",
        "    self.pos_embedding = tf.keras.layers.Embedding(input_dim=max_length, output_dim=depth)\n",
        "\n",
        "    self.token_embedding = tf.keras.layers.Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=depth,\n",
        "        mask_zero=True)\n",
        "    \n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, seq):\n",
        "    seq = self.token_embedding(seq) # (batch, seq, depth)\n",
        "\n",
        "    x = tf.range(tf.shape(seq)[1])  # (seq)\n",
        "    x = x[tf.newaxis, :]  # (1, seq)\n",
        "    x = self.pos_embedding(x)  # (1, seq, depth)\n",
        "\n",
        "    return self.add([seq,x])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II1mD-bBCdMB"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JTLiX3lKooQ"
      },
      "outputs": [],
      "source": [
        "class CausalSelfAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    # Use Add instead of + so the keras mask propagates through.\n",
        "    self.add = tf.keras.layers.Add() \n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "  \n",
        "  def call(self, x):\n",
        "    attn = self.mha(query=x, value=x,\n",
        "                    use_causal_mask=True)\n",
        "    x = self.add([x, attn])\n",
        "    return self.layernorm(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIY6Vu2pLBAO"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self,**kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    self.add = tf.keras.layers.Add() \n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "  \n",
        "  def call(self, x, y, **kwargs):\n",
        "    attn, attention_scores = self.mha(\n",
        "             query=x, value=y,\n",
        "             return_attention_scores=True)\n",
        "    \n",
        "    self.last_attention_scores = attention_scores\n",
        "\n",
        "    x = self.add([x, attn])\n",
        "    return self.layernorm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWKrl7teOnH2"
      },
      "outputs": [],
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(units=2*units, activation='relu'),\n",
        "        tf.keras.layers.Dense(units=units),\n",
        "        tf.keras.layers.Dropout(rate=dropout_rate),\n",
        "    ])\n",
        "\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "  \n",
        "  def call(self, x):\n",
        "    x = x + self.seq(x)\n",
        "    return self.layernorm(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydcW5KZZHou7"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, num_heads=1, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.self_attention = CausalSelfAttention(num_heads=num_heads,\n",
        "                                              key_dim=units,\n",
        "                                              dropout=dropout_rate)\n",
        "    self.cross_attention = CrossAttention(num_heads=num_heads,\n",
        "                                          key_dim=units,\n",
        "                                          dropout=dropout_rate)\n",
        "    self.ff = FeedForward(units=units, dropout_rate=dropout_rate)\n",
        "      \n",
        "\n",
        "  def call(self, inputs, training=False):\n",
        "    in_seq, out_seq = inputs\n",
        "\n",
        "    # Text input\n",
        "    out_seq = self.self_attention(out_seq)\n",
        "\n",
        "    out_seq = self.cross_attention(out_seq, in_seq)\n",
        "    \n",
        "    self.last_attention_scores = self.cross_attention.last_attention_scores\n",
        "\n",
        "    out_seq = self.ff(out_seq)\n",
        "\n",
        "    return out_seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lgbYrF5Csqu"
      },
      "source": [
        "### Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeWw2SFDHUfo"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "class TokenOutput(tf.keras.layers.Layer):\n",
        "  def __init__(self, tokenizer, banned_tokens=('', '[UNK]', '[START]'), **kwargs):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(\n",
        "        units=tokenizer.vocabulary_size(), **kwargs)\n",
        "    self.tokenizer = tokenizer\n",
        "    self.banned_tokens = banned_tokens\n",
        "\n",
        "    self.bias = None\n",
        "\n",
        "  def adapt(self, ds):\n",
        "    counts = collections.Counter()\n",
        "    vocab_dict = {name: id \n",
        "                  for id, name in enumerate(self.tokenizer.get_vocabulary())}\n",
        "\n",
        "    for tokens in tqdm.tqdm(ds):\n",
        "      counts.update(tokens.numpy().flatten())\n",
        "\n",
        "    counts_arr = np.zeros(shape=(self.tokenizer.vocabulary_size(),))\n",
        "    counts_arr[np.array(list(counts.keys()), dtype=np.int32)] = list(counts.values())\n",
        "\n",
        "    counts_arr = counts_arr[:]\n",
        "    for token in self.banned_tokens:\n",
        "      counts_arr[vocab_dict[token]] = 0\n",
        "\n",
        "    total = counts_arr.sum()\n",
        "    p = counts_arr/total\n",
        "    p[counts_arr==0] = 1.0\n",
        "    log_p = np.log(p)  # log(1) == 0\n",
        "\n",
        "    entropy = -(log_p*p).sum()\n",
        "\n",
        "    print()\n",
        "    print(f\"Uniform entropy: {np.log(self.tokenizer.vocabulary_size()):0.2f}\")\n",
        "    print(f\"Marginal entropy: {entropy:0.2f}\")\n",
        "\n",
        "    self.bias = log_p\n",
        "    self.bias[counts_arr==0] = -1e9\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.dense(x)\n",
        "    # TODO(b/250038731): Fix this.\n",
        "    # An Add layer doesn't work because of the different shapes.\n",
        "    # This clears the mask, that's okay because it prevents keras from rescaling\n",
        "    # the losses.\n",
        "    return x + self.bias\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzQHqANd1A6Q"
      },
      "source": [
        "The smart initialization will significantly reduce the initial loss:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGnOQyc501B2"
      },
      "outputs": [],
      "source": [
        "output_layer = TokenOutput(tokenizer, banned_tokens=('', '[UNK]', '[START]'))\n",
        "# This might run a little faster if the dataset didn't also have to load the image data.\n",
        "output_layer.adapt(train_ds.map(lambda inputs, labels: labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gq-ICN7bD-u"
      },
      "source": [
        "### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHCISYehH1f6"
      },
      "outputs": [],
      "source": [
        "class Captioner(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, tokenizer, feature_extractor, output_layer, num_layers=1,\n",
        "               units=256, max_length=50, num_heads=1, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.feature_extractor = feature_extractor\n",
        "    self.tokenizer = tokenizer\n",
        "    self.word_to_index = tf.keras.layers.StringLookup(\n",
        "        mask_token=\"\",\n",
        "        vocabulary=tokenizer.get_vocabulary())\n",
        "    self.index_to_word = tf.keras.layers.StringLookup(\n",
        "        mask_token=\"\",\n",
        "        vocabulary=tokenizer.get_vocabulary(),\n",
        "        invert=True) \n",
        "\n",
        "    self.seq_embedding = SeqEmbedding(\n",
        "        vocab_size=tokenizer.vocabulary_size(),\n",
        "        depth=units,\n",
        "        max_length=max_length)\n",
        "\n",
        "    self.decoder_layers = [\n",
        "        DecoderLayer(units, num_heads=num_heads, dropout_rate=dropout_rate)\n",
        "        for n in range(num_layers)]\n",
        "\n",
        "    self.output_layer = output_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPdb7I4h9Ulo"
      },
      "outputs": [],
      "source": [
        "  @Captioner.add_method\n",
        "  def call(self, inputs):\n",
        "    image, txt = inputs\n",
        "\n",
        "    if image.shape[-1] == 3:\n",
        "      # Apply the feature-extractor, if you get an RGB image.\n",
        "      image = self.feature_extractor(image)\n",
        "    \n",
        "    # Flatten the feature map\n",
        "    image = einops.rearrange(image, 'b h w c -> b (h w) c')\n",
        "\n",
        "\n",
        "    if txt.dtype == tf.string:\n",
        "      # Apply the tokenizer if you get string inputs.\n",
        "      txt = tokenizer(txt)\n",
        "\n",
        "    txt = self.seq_embedding(txt)\n",
        "\n",
        "    # Look at the image\n",
        "    for dec_layer in self.decoder_layers:\n",
        "      txt = dec_layer(inputs=(image, txt))\n",
        "      \n",
        "    txt = self.output_layer(txt)\n",
        "\n",
        "    return txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmM7aZQsLiyU"
      },
      "outputs": [],
      "source": [
        "model = Captioner(tokenizer, feature_extractor=mobilenet, output_layer=output_layer,\n",
        "                  units=256, dropout_rate=0.5, num_layers=2, num_heads=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGvOcLQKghXN"
      },
      "source": [
        "### Generate captions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwFcdMqC-jE2"
      },
      "outputs": [],
      "source": [
        "image_url = 'https://tensorflow.org/images/surf.jpg'\n",
        "image_path = tf.keras.utils.get_file('surf.jpg', origin=image_url)\n",
        "image = load_image(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nf1Jie9ef_Cg"
      },
      "outputs": [],
      "source": [
        "@Captioner.add_method\n",
        "def simple_gen(self, image, temperature=1):\n",
        "  initial = self.word_to_index([['[START]']]) # (batch, sequence)\n",
        "  img_features = self.feature_extractor(image[tf.newaxis, ...])\n",
        "\n",
        "  tokens = initial # (batch, sequence)\n",
        "  for n in range(50):\n",
        "    preds = self((img_features, tokens)).numpy()  # (batch, sequence, vocab)\n",
        "    preds = preds[:,-1, :]  #(batch, vocab)\n",
        "    if temperature==0:\n",
        "        next = tf.argmax(preds, axis=-1)[:, tf.newaxis]  # (batch, 1)\n",
        "    else:\n",
        "        next = tf.random.categorical(preds/temperature, num_samples=1)  # (batch, 1)\n",
        "    tokens = tf.concat([tokens, next], axis=1) # (batch, sequence) \n",
        "\n",
        "    if next[0] == self.word_to_index('[END]'):\n",
        "      break\n",
        "  words = index_to_word(tokens[0, 1:-1])\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  return result.numpy().decode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sPm96CccvHnq",
        "outputId": "63b2a11d-337f-4a8f-8a1b-5454a206e06a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a a a a\n",
            "a a a a a on a a the the a\n",
            "bunny costume records red a young\n"
          ]
        }
      ],
      "source": [
        "for t in (0.0, 0.5, 1.0):\n",
        "  result = model.simple_gen(image, temperature=t)\n",
        "  print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0FpTvaPkqON"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5IW2mWa2sAG"
      },
      "source": [
        "### Losses and metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s24im3FqxAfT"
      },
      "outputs": [],
      "source": [
        "def masked_loss(labels, preds):  \n",
        "  loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels, preds)\n",
        "\n",
        "  mask = (labels != 0) & (loss < 1e8) \n",
        "  mask = tf.cast(mask, loss.dtype)\n",
        "\n",
        "  loss = loss*mask\n",
        "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "  return loss\n",
        "\n",
        "def masked_acc(labels, preds):\n",
        "  mask = tf.cast(labels!=0, tf.float32)\n",
        "  preds = tf.argmax(preds, axis=-1)\n",
        "  labels = tf.cast(labels, tf.int64)\n",
        "  match = tf.cast(preds == labels, mask.dtype)\n",
        "  acc = tf.reduce_sum(match*mask)/tf.reduce_sum(mask)\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOhjHqgv3F2e"
      },
      "source": [
        "### Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IKDwbZOCZ-AP"
      },
      "outputs": [],
      "source": [
        "class GenerateText(tf.keras.callbacks.Callback):\n",
        "  def __init__(self):\n",
        "    image_url = 'https://tensorflow.org/images/surf.jpg'\n",
        "    image_path = tf.keras.utils.get_file('surf.jpg', origin=image_url)\n",
        "    self.image = load_image(image_path)\n",
        "\n",
        "  def on_epoch_end(self, epochs=None, logs=None):\n",
        "    print()\n",
        "    print()\n",
        "    for t in (0.0, 0.5, 1.0):\n",
        "      result = self.model.simple_gen(self.image, temperature=t)\n",
        "      print(result)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IGVLpzo13rcA",
        "outputId": "153055b0-6ace-44e2-8125-0e547e87202b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "a a a a a a a a a a a a a a a a a a\n",
            "a two running a\n",
            "girl in doorway\n",
            "\n"
          ]
        }
      ],
      "source": [
        "g = GenerateText()\n",
        "g.model = model\n",
        "g.on_epoch_end(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MjzrwGZp23xx"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    GenerateText(),\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        patience=5, restore_best_weights=True)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBaJhQpcG8u0"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBXG0dCDKO55"
      },
      "source": [
        "Configure and execute the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2OR5ZpAII__u"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "           loss=masked_loss,\n",
        "           metrics=[masked_acc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3aB0baOVMZe9",
        "outputId": "29badeda-3b2a-4868-bfb2-a6d1b74e24fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-a474d2464f59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     callbacks=callbacks)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m       _, _, filtered_flat_args = (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[0;32m--> 135\u001b[0;31m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    381\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 53\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(),\n",
        "    steps_per_epoch=100,\n",
        "    validation_data=test_ds.repeat(),\n",
        "    validation_steps=20,\n",
        "    epochs=100,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P634LfVgw-eV"
      },
      "source": [
        "Plot the loss and accuracy over the training run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6Wn8KSkUw916"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yZQ78b2Kxw-T"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQN1qT7KNqbL"
      },
      "source": [
        "## Attention plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1UQPtNTb2eu3"
      },
      "outputs": [],
      "source": [
        "result = model.simple_gen(image, temperature=0.0)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zHKOpm0w5Xto"
      },
      "outputs": [],
      "source": [
        "str_tokens = result.split()\n",
        "str_tokens.append('[END]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hX3kMGMGn_Y1"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qMUp_hmlkfV9"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('/content/th.png')\n",
        "img = cv2.resize(img, (224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nm2622bqn2U-"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6Y53Y499nZsQ"
      },
      "outputs": [],
      "source": [
        "model.simple_gen(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Rh48bm4lpD5O"
      },
      "outputs": [],
      "source": [
        "model.simple_gen(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "al0tBawYqD5l"
      },
      "outputs": [],
      "source": [
        "model.simple_gen(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XpGQSaPdqEP4"
      },
      "outputs": [],
      "source": [
        "model.simple_gen(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9UpAX18wqbB_"
      },
      "outputs": [],
      "source": [
        "model.simple_gen(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FfmoO_28qoQG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "29T8_EqaqpiB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uAg2luu6RfO"
      },
      "source": [
        "# Saving models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "35OWeXi8ACkK"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yLta3HQHqmuV"
      },
      "outputs": [],
      "source": [
        "model.save_weights('saved/model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e2JPR__57GCd"
      },
      "outputs": [],
      "source": [
        "\n",
        "# output_layer = TokenOutput(tokenizer, banned_tokens=('', '[UNK]', '[START]'))\n",
        "# # This might run a little faster if the dataset didn't also have to load the image data.\n",
        "# output_layer.adapt(train_ds.map(lambda inputs, labels: labels))\n",
        "\n",
        "# model = Captioner(tokenizer, feature_extractor=mobilenet, output_layer=output_layer,\n",
        "                #   units=256, dropout_rate=0.5, num_layers=2, num_heads=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "emTi9phgA5xZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vEjQHJcV8aHI"
      },
      "outputs": [],
      "source": [
        "tokenizer_file = 'saved/tokenizer.pkl'\n",
        "\n",
        "with open(tokenizer_file, 'wb') as f:\n",
        "    pickle.dump({\n",
        "        'config': tokenizer.get_config(),\n",
        "        'weights': tokenizer.get_weights()\n",
        "    }, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8VgHx_VGFDM"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L0qn_IBlArQY"
      },
      "outputs": [],
      "source": [
        "IMAGE_SHAPE=(224, 224, 3)\n",
        "mobilenet = tf.keras.applications.MobileNetV3Small(\n",
        "    input_shape=IMAGE_SHAPE,\n",
        "    include_top=False,\n",
        "    include_preprocessing=True)\n",
        "mobilenet.trainable=False"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "wqGXX9Dc5c0v",
        "zQICBAF4FmSL",
        "rBAagBw5p-TM",
        "8cSW4u-ORPFQ",
        "nyqH3zFwRPFi",
        "uEWM9xrYcg45",
        "XZyKygJ8S8zW",
        "GI265LiDslr2",
        "DfICM49WFpIb",
        "_ngm3SQMCaYU",
        "II1mD-bBCdMB",
        "-lgbYrF5Csqu",
        "3gq-ICN7bD-u",
        "xGvOcLQKghXN",
        "g5IW2mWa2sAG",
        "zOhjHqgv3F2e"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}